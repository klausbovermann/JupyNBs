{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine-Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Motivation, um den Lösungsweg zu optimieren"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: Cornsilk; padding: 5px 20px 20px\">\n",
    "\n",
    "In dem [Notebook](../Regression/01_RegressionOhneBias.ipynb) mussten wir während der Trainingsphase den Wert von `m` solange verändern, bis der Fehler möglichst gering war. Dabei wurde immer wieder die Vorhersagefunktion aktiviert und damit ein Mittelwert errechnet.\n",
    "\n",
    "Die Frage stellt sich jetzt, ob es vielleicht möglich ist, in der Trainingsphase schneller das Minimum der Fehlerfunktion zu bestimmen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: Cornsilk; padding: 5px 20px 20px\">\n",
    "\n",
    "Wir lassen dazu einmal den Graphen zeichnen, der sich ergibt, wenn man für gewisse Werte von m den zugehörigen Fehler berechnet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vorhersage (X,m):\n",
    "    return X*m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fehler (X, Y, m):\n",
    "    return np.average ((vorhersage (X, m) - Y)**2)\n",
    "# (Der Wert des Fehlers hängt tatsächlich nur von dem Wert von m ab,\n",
    "# da X und Y - nach dem Einlesen der Daten - konstant sind!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "X, Y = np.loadtxt(\"../Daten/schuhe.txt\", skiprows=1, unpack=True)\n",
    "\n",
    "sns.set()  # Activate Seaborn\n",
    "\n",
    "# Berechne den Fehler für m im Bereich [0 ... 3]\n",
    "alleMs = np.linspace(-1.0, 4.0, 200)\n",
    "alleFehler = [fehler(X, Y, m) for m in alleMs]\n",
    "\n",
    "# Plot m gegen den Fehler\n",
    "plt.axis([0, 3, -100, 1000])\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.xlabel(\"m\", fontsize=15)\n",
    "plt.ylabel(\"Fehler\", fontsize=15)\n",
    "plt.plot(alleMs, alleFehler, color=\"black\")\n",
    "plt.show ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: Cornsilk; padding: 5px 20px 20px\">\n",
    "\n",
    "In dem für m betrachteten Intervall [0, 3] scheint es doch einfach zu sein, das Minimum des Fehlers zu finden. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: lightblue; padding: 5px 20px 20px\">\n",
    "\n",
    "### Aufgabe: \n",
    "    \n",
    "Suche zu der Funktion mit dem Term $2x^2 + 3x + 4$ eine Stelle mit möglichst kleinem Wert, indem du in der folgenden Eingabezelle verschiedene Werte berechnen lässt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return 2*x**2 + 3*x + 4\n",
    "\n",
    "# hier bitte probieren!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: Cornsilk; padding: 5px 20px 20px\">\n",
    "\n",
    "Um das lokale Minimum systematischer zu finden, stellen wir folgende Überlegungen an:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steigung; ein wenig Analysis zur Wiederholung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: Cornsilk; padding: 5px 20px 20px\">\n",
    "\n",
    "Die Mathematik bietet folgendes an:\n",
    "> Hat man eine differenzierbare Funktion $f$, so ist $f'(x)$ die Steigung der Tangente an der Stelle `x`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: Cornsilk; padding: 5px 20px 20px\">\n",
    "\n",
    "Auch wenn du mit der Begrifflichkeit noch nicht vertraut bist:\n",
    "\n",
    "> Man nennt $f'(x)$ die ***Ableitung*** einer Funktion $f$.\n",
    "\n",
    "Das hat folgenden Sinn:\n",
    "\n",
    "> Die Ableitung $f'(x)$ einer Funktion $f$ ist ein Maß für die ***Steilheit*** des Graphen der Funktion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ableitung(term):\n",
    "    term_d = diff (term, x)\n",
    "    return term_d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: Cornsilk; padding: 5px 20px 20px\">\n",
    "\n",
    "Das kann man visualisieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true
   },
   "outputs": [],
   "source": [
    "from sympy import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x=Symbol('x')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: Cornsilk; padding: 5px 20px 20px\">\n",
    "\n",
    "Dargestellt ist in BLAU der Graph einer Funktion sowie eine Gerade, die man als ***Tangente an $f$ an der Stelle $s$*** bezeichnet.\n",
    "\n",
    "Die Steilheit der Funktion, also die Steilheit dieser Tangente, wird berechnet mit Hilfe der oben beschriebenen Ableitung."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "term = 2*x**2 + 3*x + 4\n",
    "s = 4\n",
    "\n",
    "tt = ableitung (term)\n",
    "\n",
    "f = lambdify(x, term)\n",
    "fs = lambdify(x, tt)\n",
    "\n",
    "X = np.linspace(-6, 10, 100)\n",
    "Y = f(X)\n",
    "Z = fs(X)\n",
    "\n",
    "T = fs(s) * (X-s) + f(s)\n",
    "\n",
    "\n",
    "p1 = plt.plot (X,Y)\n",
    "#p2 = plt.plot (X,Z)\n",
    "p3 = plt.plot (X,T)\n",
    "\n",
    "p4 = plt.plot (s,f(s),\"r.\")\n",
    "plt.ylim(-25, 150)\n",
    "plt.show ()\n",
    "print (\"Die Steilheit an der Stelle\", s, \"ist\", fs(s))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: lightblue; padding: 5px 20px 20px\">\n",
    "\n",
    "### Aufgabe:\n",
    "\n",
    "Probiere in der obigen Eingabezelle mit unterschiedlichen Werten für $s$ und/oder mit anderen Termen. Beobachte dabei genau die Steilheit sowie den Wert der Ableitung, der unter der Graphik angezeigt wird.\n",
    "\n",
    "Beantworte auch die Frage:\n",
    "- Für welche Werte von $s$  ist die Steilheit positiv, für welche negativ?\n",
    "\n",
    "Suche auch einen Wert für $s$, so dass die Steilheit einen Wert hat, der möglichst nahe bei Null liegt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eine wichtige Aufgabe der Analysis besteht z.B. darin, die lokalen Extrema einer Funktion zu finden.\n",
    "\n",
    "Die Analysis sagt uns dazu:\n",
    "\n",
    "> Ist $f$ eine differenzierbare Funktion. Wenn der Punkt $x_0, f(x_0)$ ein lokaler Extrempunkt ist, dann ist $f'(x_0) = 0$\n",
    "\n",
    "Also macht es Sinn, sich auf die Suche nach den Nullstellen von $f$ zu begeben."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doch ist die Gleichung $f'(x) = 0$ nicht immer algebraisch einfach zu lösen. Dann hilft folgende Überlegung, die wir an einem Beispiel einer quadratischen Funktion demonstrieren wollen. \n",
    "\n",
    "Eine quadratische Funktion, die nach oben geöffnet ist, hat immer ein lokales Minimum. Das wollen wir finden, ohne die Nullstelle der Ableitung algebraisch zu suchen. \n",
    "\n",
    "*Die algebraische Suche ist natürlich eigentlich sehr einfach, da es sich bei der Ableitung einer quadratischen Funktion um eine lineare Funktion handelt; doch wir ignorieren das hier einmal, um das Prinzip zu verdeutlichen!*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um also das lokale Minumum zu finden, starten wir an einer beliebigen Stelle $s$ und berechnen dort den Wert der Ableitung $a = f'(s)$\n",
    "\n",
    "Anschaulich ist dann klar:\n",
    "- Ist $a=0$, so hat man das Minumum gefunden.\n",
    "  - Da hier mit (ungenauen) Fließkommazahlen gearbeitet wird, wird man dies umformulieren zu $|a| < \\varepsilon$ für ein geeignetes $\\varepsilon$.\n",
    "- Ist $a > 0$, dann muss man $s$ verkleinern. Dabei verkleinert man $s$ umso mehr, je größer $a$ ist.\n",
    "- Ist dagegen $a < 0$, muss man $s$ vergrößern, und zwar umso mehr, je kleiner $a$ ist. \n",
    "\n",
    "Also kann man $s$ proportional zu $a$ vergrößern oder verkleinern. Das führt zu der Iteration \n",
    "$(s \\leftarrow s - a * d)$ mit einem Proportionalitätsfaktor $d$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "term = x**3 + 2*x**2 - 3*x + 4\n",
    "p_start = 4\n",
    "\n",
    "tt = ableitung (term)\n",
    "\n",
    "f = lambdify(x, term)\n",
    "fs = lambdify(x, tt)\n",
    "\n",
    "X = np.linspace(-5, 5, 100)\n",
    "Y = f(X)\n",
    "Z = fs(X)\n",
    "\n",
    "p = p_start\n",
    "T = fs(p) * (X-p) + f(p)\n",
    "\n",
    "\n",
    "p1 = plt.plot (X,Y)\n",
    "#p2 = plt.plot (X,Z)\n",
    "p3 = plt.plot (X,T)\n",
    "\n",
    "i = 0\n",
    "abl = fs(p)\n",
    "while (i < 1000) and (abs (abl) > 0.001):\n",
    "    # print(\"Iteration %4d => f: %.4f fs: %.4f \" % (i, f(p), fs(p)))\n",
    "    p -= fs(p) * 0.01\n",
    "    abl = fs(p)\n",
    "    i += 1\n",
    "\n",
    "print (\"Start bei x = %4f\" % p_start)\n",
    "print(\"Nach %4d Iterationen => Funktionswert: %.4f; Steigung: %.4f \" % (i, f(p), fs(p)))\n",
    "if (i > 1000):\n",
    "    print (\"Keine Lösung gefunden!\")\n",
    "else:    \n",
    "    print (\"Tiefpunkt bei ca. %4f\" % p)\n",
    "\n",
    "p4 = plt.plot (p,f(p),\"r.\")\n",
    "plt.show ()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Überwachtes Lernen; Gradienten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wir benutzen hier nochmals die Fragestellung aus dem [Notebook](../Regression/01_RegressionOhneBias.ipynb). \n",
    "Dort haben wir mit Hilfe von Trainingsläufen eine Lösung gefunden, indem der Fehler schrittweise verkleinert wurde.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(X, Y, w):\n",
    "    return 2 * np.average(X * (vorhersage(X, w) - Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def train(X, Y, iterations, lr):\n",
    "    w = 0\n",
    "    for i in range(iterations):\n",
    "        print(\"Iteration %4d => Loss: %.10f\" % (i, fehler(X, Y, w)))\n",
    "        w -= gradient(X, Y, w) * lr\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = np.loadtxt(\"../Daten/schuhe.txt\", skiprows=1, unpack=True)\n",
    "w = train(X, Y, iterations=100, lr=0.001)\n",
    "print(\"\\nw=%.10f\" % w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zum Testen wird die Fehler-Funktion (in Abhängigkeit von m):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "X, Y = np.loadtxt(\"../Daten/schuhe.txt\", skiprows=1, unpack=True)\n",
    "\n",
    "sns.set()  # Activate Seaborn\n",
    "\n",
    "# Berechne den Fehler für m im Bereich [-1 ... 4]\n",
    "alleMs = np.linspace(-1.0, 4.0, 200)\n",
    "alleFehler = [fehler(X, Y, m) for m in alleMs]\n",
    "\n",
    "# Plot m gegen Fehler\n",
    "plt.axis([0, 3, -100, 1000])\n",
    "plt.xticks(fontsize=15)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.xlabel(\"m\", fontsize=30)\n",
    "plt.ylabel(\"Fehler\", fontsize=30)\n",
    "plt.plot(alleMs, alleFehler, color=\"black\")\n",
    "\n",
    "# Put a green cross on the minimum loss\n",
    "min_index = np.argmin(alleFehler)\n",
    "plt.plot(alleMs[min_index], alleFehler[min_index], \"gX\", markersize=26)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
